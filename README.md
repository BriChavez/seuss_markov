# &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; **Dr. Seuss Flavored Markov**


<p float="center">
  <img img align="top" src="thing1.jpg" width="20%" />
  <img src="seuss_op.jpg" width="50%" /> 
  <img src="thing2.jpg" width="22%" />
</p>

<br/><br/><br/><br/>
## &emsp; **A Peek Into How Markov's Work**

&emsp; A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, "What happens next depends only on the state of affairs now."<br/>

&emsp; Markov chains have many applications as statistical models of real-world processes, such as studying cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, currency exchange rates and animal population dynamics. Markov processes are the basis for general stochastic simulation methods, which are used for simulating sampling from complex probability distributions, and have found application in Bayesian statistics, thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory and speech processing.<br/>
<br/><br/><br/><br/>

<p float="center">
<a href="https://www.youtube.com/embed/i3AkTO9HLXo"><img src="mc.jpg" alt="Markov Chains Clearly Explained! Part - 1" width="691" height="389" border="10" /></a>>
</p>



<br/><br/><br/><br/>
<img src="outputt.png" alt="Markov Scatter Graph" title="Markov Scatter Graph">
